{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preparatory tasks\n",
    "document_tree = ET.parse( './data/mondial_database.xml' )\n",
    "\n",
    "# Generate index for country (to be used for various DF's)\n",
    "index_ctry = [child.find('name').text for child in document_tree.iterfind('country')]\n",
    "\n",
    "# Create dictionary of country codes to names (for lookup in last exercise)\n",
    "list_ctry_code = [child.attrib.get('car_code') for child in document_tree.iterfind('country')]\n",
    "dict_ctry = dict(zip(list_ctry_code,index_ctry))\n",
    "\n",
    "# Generate index for ethnic groups (for exercise 3)\n",
    "index_ethnic = []\n",
    "for element_ctry in document_tree.iterfind('country'):\n",
    "    for element_ethnic in element_ctry.iterfind('ethnicgroup'):\n",
    "        index_ethnic.append(element_ethnic.text)\n",
    "index_ethnic = list(set(index_ethnic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Countries with Lowest Infant Mortality Rates\n",
      "===============================================\n",
      "Monaco            1.81\n",
      "Japan             2.13\n",
      "Norway            2.48\n",
      "Bermuda           2.48\n",
      "Norway            2.48\n",
      "Bermuda           2.48\n",
      "Singapore         2.53\n",
      "Sweden            2.60\n",
      "Czech Republic    2.63\n",
      "Hong Kong         2.73\n",
      "Macao             3.13\n",
      "Iceland           3.15\n",
      "Name: infant_mortality2, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise #1\n",
    "df1 = pd.DataFrame(index=index_ctry,columns=['infant_mortality'])\n",
    "\n",
    "# insert infant mortality rate per country (if there is one)\n",
    "for child in document_tree.iterfind('country'):\n",
    "    country = child.find('name').text\n",
    "    infant_mortality = [child2.text for child2 in child.iterfind('infant_mortality')]\n",
    "    if infant_mortality:\n",
    "        df1.loc[country] = float(infant_mortality[0])\n",
    "    else:\n",
    "        df1.loc[country] = np.nan\n",
    "df1['infant_mortality2'] = df1['infant_mortality'].astype(float)\n",
    "print(\"10 Countries with Lowest Infant Mortality Rates\")\n",
    "print(\"===============================================\")\n",
    "print(df1.nsmallest(10,'infant_mortality2')['infant_mortality2'])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Cities with the Largest Populations\n",
      "======================================\n",
      "Shanghai     22315474.0\n",
      "Istanbul     13710512.0\n",
      "Mumbai       12442373.0\n",
      "Moskva       11979529.0\n",
      "Beijing      11716620.0\n",
      "SÃ£o Paulo    11152344.0\n",
      "Tianjin      11090314.0\n",
      "Guangzhou    11071424.0\n",
      "Delhi        11034555.0\n",
      "Shenzhen     10358381.0\n",
      "Name: population2, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "df2 = pd.DataFrame([],columns=['population'])\n",
    "\n",
    "# City can be the child of the country or child of province,\n",
    "# which is a child of the country.\n",
    "# Assumption: Last population record is most current population\n",
    "for element_ctry in document_tree.iterfind('country'):\n",
    "    for element_city in element_ctry.iterfind('city'):\n",
    "        city = element_city.find('name').text\n",
    "        pop_current = np.nan\n",
    "        for element_pop in element_city.iterfind('population'):\n",
    "            pop_current = element_pop.text\n",
    "        if pop_current:\n",
    "            population = pop_current\n",
    "        else:\n",
    "            population = np.nan\n",
    "        df2.loc[city]= population\n",
    "    for element_prov in element_ctry.iterfind('province'):\n",
    "        for element_city in element_prov.iterfind('city'):\n",
    "            city = element_city.find('name').text\n",
    "            pop_current = np.nan\n",
    "            for element_pop in element_city.iterfind('population'):\n",
    "                pop_current = np.nan\n",
    "                pop_current = element_pop.text\n",
    "            if pop_current:\n",
    "                population = pop_current\n",
    "            else:\n",
    "                population = np.nan\n",
    "            df2.loc[city]= population \n",
    "            \n",
    "df2['population2'] = df2['population'].astype(float)  \n",
    "print(\"10 Cities with the Largest Populations\")\n",
    "print(\"======================================\")\n",
    "print(df2.nlargest(10,'population2')['population2'])\n",
    "print(\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Ethnic Groups with Largest Overall Population\n",
      "================================================\n",
      "               ethnic_pop\n",
      "Han Chinese  1.245059e+09\n",
      "Indo-Aryan   8.718156e+08\n",
      "European     4.948722e+08\n",
      "African      3.183251e+08\n",
      "Dravidian    3.027137e+08\n",
      "Mestizo      1.577344e+08\n",
      "Bengali      1.467769e+08\n",
      "Russian      1.318570e+08\n",
      "Japanese     1.265342e+08\n",
      "Malay        1.219936e+08\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3     \n",
    "\n",
    "# Ethnic group is only at the country level, so need to sum it up\n",
    "# after gathering all ethnicgroup records for every country.\n",
    "index_df3 = pd.MultiIndex.from_product([index_ctry,index_ethnic],names=['country','ethnic_group'])\n",
    "df3 = pd.DataFrame(index=index_df3,columns=['population','percentage'])\n",
    "        \n",
    "for element_ctry in document_tree.iterfind('country'):  \n",
    "    country = element_ctry.find('name').text\n",
    "    \n",
    "    # get last population value\n",
    "    pop_current = np.nan\n",
    "    for element_pop in element_ctry.iterfind('population'):\n",
    "        pop_current = element_pop.text\n",
    "        \n",
    "    for element_ethnic in element_ctry.iterfind('ethnicgroup'):\n",
    "        ethnic_group = element_ethnic.text\n",
    "        ethnic_attrib = element_ethnic.attrib\n",
    "        ethnic_perc = ethnic_attrib.get('percentage')\n",
    "        df3.loc[country,ethnic_group]=[pop_current,ethnic_perc]\n",
    "\n",
    "# apply percentage to country's population      \n",
    "df3['ethnic_pop'] = df3['population'].astype(float) * df3['percentage'].astype(float) / 100\n",
    "\n",
    "# remove extra records\n",
    "df3_cond = ~df3['ethnic_pop'].isnull()\n",
    "df3_clean = df3[df3_cond]['ethnic_pop']\n",
    "\n",
    "df3_ethnic = pd.DataFrame([],index=index_ethnic,columns=['ethnic_pop'],dtype=float)\n",
    "\n",
    "for ethnic_group in index_ethnic:\n",
    "    df3_ethnic.loc[ethnic_group] = df3_clean.loc[:,ethnic_group].sum()\n",
    "    \n",
    "print(\"10 Ethnic Groups with Largest Overall Population\")\n",
    "print(\"================================================\")\n",
    "print(df3_ethnic.nlargest(10,'ethnic_pop'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest river is Amazonas, located in CO BR PE\n",
      "Largest lake is Caspian Sea, located in R AZ KAZ IR TM\n",
      "Highest airport is El Alto Intl, located in BOL\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "index_river = [element_river.find('name').text for element_river in document_tree.iterfind('river')]\n",
    "index_lake = [element_lake.find('name').text for element_lake in document_tree.iterfind('lake')]\n",
    "index_airport = [element_airport.find('name').text for element_airport in document_tree.iterfind('airport')]\n",
    "\n",
    "df_river = pd.DataFrame([],index=index_river,columns=['countries','length'])\n",
    "df_lake = pd.DataFrame([],index=index_lake,columns=['countries','area'])\n",
    "df_airport = pd.DataFrame([],index=index_airport,columns=['countries','elevation'])\n",
    "\n",
    "for element_river in document_tree.iterfind('river'):\n",
    "    river_name = element_river.find('name').text\n",
    "    river_countries = element_river.attrib.get('country')\n",
    "    find_river_length = element_river.find('length')\n",
    "    if find_river_length != None:\n",
    "        river_length = find_river_length.text\n",
    "    else:\n",
    "        river_length = -1\n",
    "    df_river.loc[river_name] = [river_countries,river_length]\n",
    "df_river['length_new'] = df_river['length'].astype(float)\n",
    "countries = df_river.nlargest(1,'length_new')['countries']\n",
    "print(\"Longest river is \" + countries.index[0] + \", located in \" + countries.values[0])\n",
    "\n",
    "for element_lake in document_tree.iterfind('lake'):\n",
    "    lake_name = element_lake.find('name').text\n",
    "    lake_countries = element_lake.attrib.get('country')\n",
    "    find_lake_area = element_lake.find('area')\n",
    "    if find_lake_area != None:\n",
    "        lake_area = find_lake_area.text\n",
    "    else:\n",
    "        lake_area = -1\n",
    "    df_lake.loc[lake_name] = [lake_countries,lake_area]\n",
    "df_lake['area_new'] = df_lake['area'].astype(float)\n",
    "countries = df_lake.nlargest(1,'area_new')['countries']\n",
    "print(\"Largest lake is \" + countries.index[0] + \", located in \" + countries.values[0])\n",
    "\n",
    "for element_airport in document_tree.iterfind('airport'):\n",
    "    airport_name = element_airport.find('name').text\n",
    "    airport_countries = element_airport.attrib.get('country')\n",
    "    find_airport_elevation = element_airport.find('elevation')\n",
    "    if find_airport_elevation != None:\n",
    "        airport_elev = find_airport_elevation.text\n",
    "    else:\n",
    "        airport_elev = -1\n",
    "    df_airport.loc[airport_name] = [airport_countries,airport_elev]\n",
    "df_airport['elevation_new'] = df_airport['elevation'].astype(float)\n",
    "countries = df_airport.nlargest(1,'elevation_new')['countries']\n",
    "print(\"Highest airport is \" + countries.index[0] + \", located in \" + countries.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
